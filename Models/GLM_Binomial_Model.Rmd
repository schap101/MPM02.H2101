---
title: "GLM_Binomial_Model"
author: "Sofie HÃ¼rlimann"
output:
  html_document:
    toc: yes
    toc_depth: 4
    number_sections: yes
  pdf_document:
    toc: yes
    toc_depth: '4'
---

# GLM Binomial and GLM Poisson

## Set up
Installing and importing the needed packages and libraries
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)    # For knitting document and include_graphics function
library(ggplot2)  # For plotting
#install.packages("png")
library(png)
# install.packages("caret")
# install.packages("dplyr")
library("caret")
library("magrittr")
library("dplyr")
# install.packages("mosaicCore")
library("mosaicCore")
library(readr)
# install.packages("Metrics")
library(Metrics)

```



## Reading in the daily data as "day" and the hourly data as "hour" and having a look at it
```{r}

# day_0 <- read_csv(".../Data/day.csv")
head(day_0)


```


````{r}
# hour_0 <- read_csv(".../Data/hour.csv")
head(hour_0)
```

For this model we are also going to drop the data from the 27th and 28th of August 2011, for the reasons shown in the last chapter.

```{r}
day <- day_0[!(day_0$dteday=="2011-08-27" | day_0$dteday=="2011-08-28"),]

hour <- hour_0[!(hour_0$dteday=="2011-08-27" | hour_0$dteday=="2011-08-28"),]
```




````{r}
str(hour)
````

````{r}
str(day)
````

## Plotting the data
First we have a look at how the different variables are corresponding with number of bicycles, that are being used 
```{r , echo=True}
pairs.daily <- pairs(cnt ~ dteday + season + yr + mnth + holiday + weekday + workingday + weathersit + temp + atemp + hum + windspeed + casual + registered, data = day, upper.panel = panel.smooth)


```

```{r, echo=True}
pairs.hour <- pairs(cnt ~ dteday + season + yr + mnth + hr+ holiday + weekday + workingday + weathersit + temp + atemp + hum + windspeed + casual + registered, data = hour, upper.panel = panel.smooth)


```


What we can see here, is that it looks like there is an uptake in bicylce usage when
the temperature is rising (up to a certain point). When it gets too hot, the demand seems to lower again. This also corresponds in the usage during the different seasons, with the least demand in winter.

The variable for casual or registered users is less of importance here, as it does not necessarily help with the prediction of the bike demand. Especially as we don't see drastically different behaviour regarding usage. Just from the graph above one could assume, that it is slightly more likely that registered users use the bikes also in more extreme weather situations (hot, cold, windy, etc.).

So let's have another look at the following variables:
- season
- mnth
- hour
- weathersit
- temp
- atemp
- hum
- windspeed

```{r, echo=True}
pairs.hour.new <- pairs(cnt ~ season + mnth + hr+ weathersit + temp + atemp + hum + windspeed, data = hour, upper.panel = panel.smooth)

```

```{r, echo=True}
boxplot(cnt ~ season, data = day)

```
```{r, echo=True}
boxplot(cnt ~ mnth, data = day)

```

It looks like late winter/early spring is the least popular time for bike rentals. Let's check, if it might have sth to do with the weather.

```{r, echo=True}
# I'm having a look at the temperature per month
boxplot(temp ~ mnth, data = day)

```

The temperature shows the same pattern with the lowest temperatures being in late winter/early spring.

```{r pressure, echo=True}
# I'm having a look at the windspeed per month
boxplot(windspeed ~ mnth, data = day)

```
For the windspeed we cannot say the same. 

```{r, echo=True}
# I'm having a look at the temperature per month
boxplot(hum ~ mnth, data = day)

```

Neither for the humidity


## Creating training an testing sets

First we divide the data into a training and a testing set. We use 80% of the data to train the model and 20% to test it. Furthermore we divide the testing set into one we use for prediction and one to check those predictions.

```{r}

set.seed(123)
indices.day <- createDataPartition(day$cnt, p = .8, list = F) 
 
day.train <- day %>% slice(indices.day) 
day.test_in <- day %>% slice(-indices.day) %>% select(-cnt) 
day.test_truth <- day %>% slice(-indices.day) %>% pull(cnt)


set.seed(123)
indices.hour <- createDataPartition(hour$cnt, p = .8, list = F) 
 
hour.train <- hour %>% slice(indices.hour) 
hour.test_in <- hour %>% slice(-indices.hour) %>% select(-cnt) 
hour.test_truth <- hour %>% slice(-indices.hour) %>% pull(cnt)



```



## Creating a binomial model

First we have a look at a simple quasibinomial model, with the assumption that there are no interactions and all effects are linear. As we only have two binary variables, we are only going to check those two here. We use ilogit() as we need the count numbers as a value between 0 and 1.

```{r}

glm.daily <- glm(ilogit(cnt) ~ holiday +  workingday , data = day,
family = "quasibinomial")

summary(glm.daily)
```

If it is a working day or not does not seem to have a significant impact on the bike usage.

```{r}
glm.binomial.hour.1 <- glm(ilogit(cnt) ~ dteday + season + yr + mnth + hr+ holiday + weekday + workingday + weathersit + temp + atemp + hum + windspeed, data = hour,
family = "quasibinomial")

summary(glm.binomial.hour.1)
```


We decided to take out the holidays, as there are only very few anyways, the assumed temperature (atemp) as it is very close to the temperature (temp) and also very dependent on the temperature, humidity and wind speed. We also took out the year, as this will not help us with our decision.

```{r}
glm.binomial.hour.2 <- glm(ilogit(cnt) ~ dteday + season + mnth + hr+ + weekday + workingday + weathersit + temp + hum + windspeed, data = hour,
family = "quasibinomial")

summary(glm.binomial.hour.2)
```



## Creating a Poisson Model

```{r}
glm.pois.hour <- glm(cnt ~ dteday + season + yr + mnth + hr+ holiday + weekday + workingday + weathersit + temp + atemp + hum + windspeed, data = hour,
family = "quasipoisson")

summary(glm.pois.hour)
```

Here it looks like quite some factors seem to be significant for the number of bikes used.
With the temperature and the assumed temperature being very similar, we drop the assumed temperature from the model, with the measured temperature being more tangible. 


```{r}
glm.pois2.hour <- glm(cnt ~ dteday + season + yr + mnth + hr+ holiday + weekday + workingday + weathersit + temp + hum + windspeed, data = hour,
family = "quasipoisson")

summary(glm.pois2.hour)

```
Now let's look at it one more time, without the year (as we only have data from two years) and without the holidays (as there are only very few of them).

```{r}
glm.pois3.hour <- glm(cnt ~ dteday + season + mnth + hr + weekday + workingday + weathersit + temp + hum + windspeed, data = hour.train,
family = "quasipoisson")

summary(glm.pois3.hour)

```

### Fitting the poisson model with "train" data 
```{r}
lm.poisson.1 <- lm(cnt ~ dteday + season + yr + mnth + hr + holiday + weekday + workingday + weathersit + temp + hum + windspeed, data=hour)

lm.poisson.train.1 <- lm(formula = formula(lm.poisson.1), data = hour.train)
```

making prediction on the test data 
```{r}
predicted.poisson.test.1 <- predict(lm.poisson.train.1, newdata = hour.test_in)
```

rmse(actual, predicted)
```{r}
rmse(hour.test_truth, predicted.poisson.test.1)
```
Having a root mean square error (RMSE) of 139 when we have numbers of about 0 to about 500 is definitely very good. Let's have a look at our prediction and the true data.



```{r, fig.keep='all'}

plot(hour.test_in$dteday,predicted.poisson.test.1,type="l",col="red")
lines(hour.test_in$dteday,hour.test_truth,type="p",col="green")
```
Here we see our predictions in red and the actual numbers in green. 

```{r}
summary(lm.poisson.1)

```

As hourly numbers vary strongly, we want to see if this model would fit better on a daily basis.


```{r}
lm.poisson.2 <- lm(cnt ~ dteday + season + yr + mnth + holiday + weekday + workingday + weathersit + temp + hum + windspeed, data=day)

lm.poisson.train.2 <- lm(formula = formula(lm.poisson.2), data = day.train)
```

making prediction on the test data 
```{r}
predicted.poisson.test.2 <- predict(lm.poisson.train.2, newdata = day.test_in)
```

Checking RMSE
```{r}
rmse(day.test_truth, predicted.poisson.test.2)
```
Here we have a RMSE of 811, which is higher than above in total, but as we are looking at daily data here, with numbers up to above 8000, this seems to be a better fit.



```{r, fig.keep='all', echo=FALSE}

plot(day.test_in$dteday,predicted.poisson.test.2,type="l",col="red")
lines(day.test_in$dteday,day.test_truth,type="l",col="green")
```
When looking at the predictions (red) in comparison to the true data (green) it does not look too bad.


```{r}
summary(lm.poisson.2)

```


To see, if a variable is not needed, the model was tested by dropping only one of the predictors for each run through. But the best result was achieved by using all the predictors.

```{r, echo=False}
lm.poisson.3 <- lm(cnt ~ dteday + season  + mnth +  weekday + holiday + workingday +  weathersit + temp + hum + windspeed, data=day)

lm.poisson.train.3 <- lm(formula = formula(lm.poisson.3), data = day.train)

# making prediction on the test data 

predicted.poisson.test.3 <- predict(lm.poisson.train.3, newdata = day.test_in)

# Checking RMSE

# rmse(day.test_truth, predicted.poisson.test.3)

```










